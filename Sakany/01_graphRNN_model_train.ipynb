{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for graph generation (topology) - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose backend for matplotlib\n",
    "# -----------------------------\n",
    "from IPython import get_ipython\n",
    "# get_ipython().run_line_magic('matplotlib', 'widget')\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# Or simply:\n",
    "# %matplotlib widget\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load local functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Load local functions...')\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(1, '../utils/')\n",
    "\n",
    "# from graph_utils import *\n",
    "# from graph_rnn import *\n",
    "# from ml_utils import *\n",
    " \n",
    "with open('../utils/graph_utils.py') as f: exec(f.read())\n",
    "with open('../utils/graph_rnn.py') as f: exec(f.read())\n",
    "with open('../utils/ml_utils.py') as f: exec(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parameters\n",
    "\n",
    "Some parameters (dimension / attribute considered and indexes / parameters for plotting graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Load parameters...')\n",
    "\n",
    "# from params import *\n",
    "\n",
    "with open('params.py') as f: exec(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output settings\n",
    "For saving data set and model (once trained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Define output settings...')\n",
    "\n",
    "# Output directory (for saving)\n",
    "# -----------------------------\n",
    "out_dir = 'out_graphRNN_model' # output directory\n",
    "\n",
    "fig_dir = 'fig'      # PARAMS\n",
    "\n",
    "plt_show = True      # PARAMS (show graphics 2D ?)\n",
    "# off_screen = False   # PARAMS (show graphics 3D ?)\n",
    "\n",
    "save_fig_png = True  # PARAMS\n",
    "fig_prefix = '01'    # PARAMS\n",
    "\n",
    "fig_counter = 0\n",
    "\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "if not os.path.isdir(fig_dir):\n",
    "    os.mkdir(fig_dir)\n",
    "    \n",
    "# Files for saving data set (pickle) (see further)\n",
    "# ------------------------------------------------\n",
    "filename_data_set = os.path.join(out_dir, f'data_set.pickle')\n",
    "\n",
    "# Files for saving network (rnn_G and rnn_E) (see further)\n",
    "# --------------------------------------------------------\n",
    "filename_hyper_param_G = os.path.join(out_dir, 'rnn_G_hyper_params.txt')\n",
    "filename_hyper_param_E = os.path.join(out_dir, 'rnn_E_hyper_params.txt')\n",
    "\n",
    "filename_param_G = os.path.join(out_dir, 'rnn_G.params')\n",
    "filename_param_E = os.path.join(out_dir, 'rnn_E.params')\n",
    "\n",
    "# Files for saving loss and lr (see further)\n",
    "# -------------------------------------------\n",
    "filename_loss_lr = os.path.join(out_dir, 'rnn_loss_lr.pickle')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read graph collection - training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Read data set (collection of subgraphs)...')\n",
    "\n",
    "# Read from text files (only position attribute)\n",
    "# ----\n",
    "# Files\n",
    "data_dir = 'data_gen'\n",
    "filename_base = 'graph_collection_data_set'\n",
    "\n",
    "# Load graph list\n",
    "G_list = load_networkx_graph_list(\n",
    "    data_dir, filename_base, \n",
    "    suffix_nodes='_nodes.dat', \n",
    "    suffix_edges='_links.dat', \n",
    "    delimiter_nodes=' ',  \n",
    "    delimiter_edges=' ',\n",
    "    node_attrs=['pos'],\n",
    "    node_attrs_ind=[tuple(range(dim))],\n",
    "    nodet_attrs_type=['float'],\n",
    "    start_id_at_0=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show first graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot data set (collection of subgraphs) (topology)...')\n",
    "\n",
    "# Plot first graphs - 2d - topology only\n",
    "# ======================================\n",
    "kwds = kwds_multi.copy()\n",
    "\n",
    "figsize = figsize_multi\n",
    "# -----\n",
    "\n",
    "ng = 16\n",
    "\n",
    "ng = min(len(G_list), ng)\n",
    "nr = int(np.sqrt(ng))\n",
    "nc = ng//nr + (ng%nr>0)\n",
    "\n",
    "# Plot\n",
    "# ----\n",
    "plt.subplots(nr, nc, figsize=figsize)\n",
    "for i, G in enumerate(G_list[:ng]):\n",
    "    plt.subplot(nr, nc, i+1)\n",
    "    networkx.draw(G, with_labels=False, **kwds)\n",
    "    plt.title(f'n_nodes={G.number_of_nodes()}')\n",
    "\n",
    "for i in range(ng, nr*nc):\n",
    "    plt.subplot(nr, nc, i+1)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle(f'graphRNN - train set')\n",
    "\n",
    "if save_fig_png:\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_dir}/{fig_prefix}_{fig_counter:02d}_graphRNN_train_set.png')\n",
    "    fig_counter = fig_counter+1\n",
    "\n",
    "if plt_show:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of graphs in list: {len(G_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Define the data set for graphRNN...')\n",
    "\n",
    "# Data set\n",
    "# --------\n",
    "G_nsample = np.full((len(G_list), ), 1) # number of times each graph in the list is sampled\n",
    "                                          # sum(G_nsample) gives the size of the data set\n",
    "# Parameters for encoding adjacency matrix\n",
    "use_bfs = True\n",
    "max_n_nodes = None \n",
    "max_prev_node = None\n",
    "calc_max_prev_node_kwargs={'nsample':10000, 'quantile':1.0, 'seed':134}\n",
    "\n",
    "data_set = Graph_sequence_sampler_data_set(\n",
    "    G_list, G_nsample, use_bfs=use_bfs,\n",
    "    max_n_nodes=max_n_nodes, max_prev_node=max_prev_node,\n",
    "    calc_max_prev_node_kwargs=calc_max_prev_node_kwargs)\n",
    "\n",
    "print(f'Data set:\\n\\\n",
    "   size = {len(data_set)}\\n\\\n",
    "   max_n_nodes   = {data_set.max_n_nodes:5d}\\n\\\n",
    "   max_prev_node = {data_set.max_prev_node:5d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Get array of number of nodes in data set...')\n",
    "\n",
    "# Get array of number of nodes in data set (via data loader, see below)\n",
    "data_set_n_nodes = []\n",
    "batch_size = 500\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, shuffle=False)\n",
    "for _, n_nodes in data_loader:\n",
    "    data_set_n_nodes = data_set_n_nodes + n_nodes.tolist()\n",
    "\n",
    "data_set_n_nodes = np.asarray(data_set_n_nodes)\n",
    "\n",
    "# Get mean, min, max number of nodes in data set\n",
    "data_set_n_nodes_mean = data_set_n_nodes.mean()\n",
    "data_set_n_nodes_std = data_set_n_nodes.std()\n",
    "data_set_n_nodes_min  = data_set_n_nodes.min()\n",
    "data_set_n_nodes_max  = data_set_n_nodes.max()\n",
    "\n",
    "print(f'Data set - number of nodes - mean: {data_set_n_nodes_mean:9.3f}')\n",
    "print(f'Data set - number of nodes - std : {data_set_n_nodes_std:9.3f}')\n",
    "print(f'Data set - number of nodes - min : {data_set_n_nodes_min:9.3f}')\n",
    "print(f'Data set - number of nodes - max : {data_set_n_nodes_max:9.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data via a data loader, and plot first encoded adjacency matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Define data loader...')\n",
    "\n",
    "# Data loader (pytorch)\n",
    "# ---------------------\n",
    "batch_size = 6\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot first batches (topology)...')\n",
    "\n",
    "torch.random.manual_seed(293) # -> for reproducibility of batches delivered by the data loader (if needed)\n",
    "\n",
    "figsize = figsize_lh4\n",
    "\n",
    "# Figure\n",
    "for i, (x, n_nodes) in enumerate(data_loader):\n",
    "    if i == 3:\n",
    "        break\n",
    "    plt.subplots(1, batch_size, figsize=figsize)\n",
    "    #plt.clf() # clear figure\n",
    "    plt.suptitle(f'Encoding adj. matrix (max_prev_node={data_set.max_prev_node})')\n",
    "    for j in range(len(x)):\n",
    "        plt.subplot(1, batch_size, j+1)\n",
    "        m = x[j, :n_nodes[j]-1, :] # encoded adj. matrix\n",
    "        plt.imshow(m, origin='upper', extent=[0.5, m.shape[1]+0.5, m.shape[0]+0.5, 0.5], interpolation='none')\n",
    "        plt.gca().set_aspect(.5)\n",
    "        plt.title(f'Batch #{i} : {j}')\n",
    "    for j in range(len(x), batch_size):\n",
    "        plt.subplot(1, batch_size, j+1)\n",
    "        plt.axis('off')\n",
    "\n",
    "    if save_fig_png:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{fig_dir}/{fig_prefix}_{fig_counter:02d}_graphRNN_train_set_enc_ad_mat_batch_{i}.png')\n",
    "        # fig_counter = fig_counter+1\n",
    "\n",
    "    if plt_show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "if save_fig_png:\n",
    "    fig_counter = fig_counter+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model for graph generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model (design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Define the model (design)...')\n",
    "\n",
    "# RNN model for graph generation\n",
    "# ------------------------------\n",
    "# Two RNN models imbricated: rnn_G, rnn_E\n",
    "\n",
    "# class RNN_model: see graph_rnn.py\n",
    "\n",
    "# rnn_G (RNN model at graph level)\n",
    "# ================================\n",
    "# Hyper parameters (design of the model)\n",
    "rnn_G_hyper_params = dict(\n",
    "    input_size        = data_set.max_prev_node,   # FIXED (must not be changed!)\n",
    "    embed_input       = True,\n",
    "    embed_input_size  = 64,    # used if rnn_G_embed_input=True\n",
    "\n",
    "    hidden_size       = 48,\n",
    "\n",
    "    has_output        = True,   \n",
    "    embed_output      = True,  # used if rnn_G_has_output=True\n",
    "    embed_output_size = 16,    # used if rnn_G_has_output=True and rnn_G_embed_output=True\n",
    "    output_size       = 32,    # used if rnn_G_has_output=True\n",
    "                                    # note: if rnn_G_has_output=False, then \n",
    "                                    # rnn_G.output_size is set to rnn_G_hidden_size\n",
    "\n",
    "    num_layers        = 4,\n",
    "    rnn_type          = 'GRU', # {'RNN', 'GRU', 'LSTM'}\n",
    "    dropout           = 0.0\n",
    ")\n",
    "\n",
    "# RNN model\n",
    "rnn_G = RNN_model(**rnn_G_hyper_params)\n",
    "\n",
    "# rnn_E (RNN model at edge level)\n",
    "# ===============================\n",
    "# Hyper parameters (design of the model)\n",
    "rnn_E_hyper_params = dict(\n",
    "    input_size        = 1,     # FIXED (must not be changed!)\n",
    "    embed_input       = True,\n",
    "    embed_input_size  = 24,    # used if rnn_E_embed_input=True\n",
    "\n",
    "    hidden_size       = rnn_G.output_size,   # FIXED (must not be changed!)\n",
    "\n",
    "    has_output        = True,   \n",
    "    embed_output      = True,  # used if rnn_E_has_output=True\n",
    "    embed_output_size = 36,    # used if rnn_E_has_output=True and rnn_E_embed_output=True\n",
    "    output_size       = 1,     # used if rnn_E_has_output=True / FIXED (must not be changed!)\n",
    "                                    # note: if rnn_E_has_output=False, then \n",
    "                                    # rnn_E.output_size is set to rnn_E_hidden_size\n",
    "                                    # which should be 1 in this case\n",
    "\n",
    "    num_layers        = 4,\n",
    "    rnn_type          = 'GRU', # {'RNN', 'GRU', 'LSTM'}\n",
    "    dropout           = 0.0\n",
    ")\n",
    "\n",
    "# RNN model\n",
    "rnn_E = RNN_model(**rnn_E_hyper_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model (hyper parameters and parameters) - if existing and already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print('Load the model (hyper parameters and parameters) (graphRNN)...')\n",
    "\n",
    "# # Load model\n",
    "\n",
    "# # rnn_G \n",
    "# # =====\n",
    "# # Hyper parameters (design of the model)\n",
    "# with open(filename_hyper_param_G, 'r') as f: rnn_G_hyper_params = eval(f.read())\n",
    "\n",
    "# # RNN model (parameters)\n",
    "# rnn_G = RNN_model(**rnn_G_hyper_params)\n",
    "# rnn_G.load_state_dict(torch.load(filename_param_G))\n",
    "\n",
    "# # rnn_E \n",
    "# # =====\n",
    "# # Hyper parameters (design of the model)\n",
    "# with open(filename_hyper_param_E, 'r') as f: rnn_E_hyper_params = eval(f.read())\n",
    "\n",
    "# # RNN model (parameters)\n",
    "# rnn_E = RNN_model(**rnn_E_hyper_params)\n",
    "# rnn_E.load_state_dict(torch.load(filename_param_E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print('Load loss and lr...')\n",
    "\n",
    "# # Load loss and lr\n",
    "# with open(filename_loss_lr, 'rb') as f: loss, lr_used_G, lr_used_E = pickle.load(file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Display the model (graphRNN)...')\n",
    "\n",
    "print('\\n')\n",
    "print('rnn_G\\n-----')\n",
    "print(rnn_G)\n",
    "print(f'Number of (learnable) params: {nb_net_params(rnn_G)}')\n",
    "\n",
    "print('\\n')\n",
    "print('rnn_E\\n-----')\n",
    "print(rnn_E)\n",
    "print(f'Number of (learnable) params: {nb_net_params(rnn_E)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_G.state_dict() # display parameters\n",
    "# rnn_E.state_dict() # display parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-initialize the model parameters (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[Re-]initialize the model parameters...')\n",
    "\n",
    "# Re-initialize the model parameters (if needed)\n",
    "# -----------------------_----------------------\n",
    "# Re-initialize rnn_G parameters\n",
    "rnn_G_seed = 857\n",
    "torch.random.manual_seed(rnn_G_seed)\n",
    "# reset_all_parameters(rnn_G)\n",
    "rnn_G.init_weights()\n",
    "\n",
    "# Re-initialize rnn_E parameters\n",
    "rnn_E_seed = 985\n",
    "torch.random.manual_seed(rnn_E_seed)\n",
    "# reset_all_parameters(rnn_E)\n",
    "rnn_E.init_weights()\n",
    "\n",
    "# print('rnn_G parameters\\n-------------')\n",
    "# for p in rnn_G.parameters():\n",
    "#     print(f'- shape:', p.data.shape)\n",
    "#     # print(f'- values:', p.data)\n",
    "\n",
    "# print('rnn_E parameters\\n--------------------')\n",
    "# for p in rnn_E.parameters():\n",
    "#     print(f'- shape:', p.data.shape)\n",
    "#     # print(f'- values:', p.data)\n",
    "\n",
    "# Initialize lists for sotring loss, lr\n",
    "# -------------------------------------\n",
    "loss = []\n",
    "lr_used_G, lr_used_E = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train the model...')\n",
    "\n",
    "# Re-launch as many times as needed (and change the settings below if needed)!\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# Settings\n",
    "# ========\n",
    "\n",
    "# Batch size, number of epochs\n",
    "# ----------------------------\n",
    "batch_size = 50\n",
    "num_epochs = int(5.0*(data_set_n_nodes_mean+3*data_set_n_nodes_std))\n",
    "print_epoch = 1\n",
    "\n",
    "print(f'... num_epochs = {num_epochs}')\n",
    "\n",
    "# Optimizer for rnn_G\n",
    "# -------------------\n",
    "# # - 1. Stochastic Gradient Descent (SGD)\n",
    "# lr_G = 0.3             # learning rate\n",
    "# weight_decay_G = 0.001 # L2-regularization\n",
    "# momentum_G = 0.0       # momentum\n",
    "# optimizer_G = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "# - 2. Adam\n",
    "lr_G = 0.0025           # learning rate; default: lr=0.001\n",
    "betas_G = (0.9, 0.999)   # betas parameters; default: betas=(0.9, 0.999)\n",
    "eps_G = 1.e-8          # epsilon parameter; default: 1.e-8\n",
    "weight_decay_G = 0.0   # L2-regularization; default: 0.0\n",
    "optimizer_G = torch.optim.Adam(rnn_G.parameters(), lr=lr_G, betas=betas_G, eps=eps_G, weight_decay=weight_decay_G)\n",
    "# ...\n",
    "\n",
    "# Learning rate scheduler for rnn_G\n",
    "# ---------------------------------\n",
    "# # - 1. CosineAnnealingLR\n",
    "# lr_init_G = lr_G\n",
    "# T_max_G = num_epochs\n",
    "# eta_min_G = lr_init_G / 10.\n",
    "# lr_scheduler_G = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_G, T_max=T_max_G, eta_min=eta_min_G, last_epoch=-1, verbose=False)\n",
    "# # Essentially, with eta_max = lr_init, at epoch t, the learning rate is set to\n",
    "# #    eta_t = eta_min + 1/2 * (eta_max - eta_min) * (1 + cos(t/T_max*pi))\n",
    "#\n",
    "# - 2. CosineAnnealingWarmRestarts\n",
    "lr_init_G = lr_G\n",
    "eta_min_G = lr_init_G / 10.\n",
    "T_mult_G = 2\n",
    "nrestart_G = 3\n",
    "T_0_G = int(np.ceil(num_epochs * (T_mult_G-1) / (T_mult_G**(nrestart_G+1)-1)))\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer_G, T_0=T_0_G, T_mult=T_mult_G, eta_min=eta_min_G, last_epoch=-1, verbose=False)\n",
    "# Essentially, with eta_max = lr_init, at epoch t, the learning rate is set to\n",
    "#    eta_t = eta_min + 1/2 * (eta_max - eta_min) * (1 + cos(T_cur/T_i*pi))\n",
    "# where\n",
    "#    T_cur: the number of epochs since the last restart\n",
    "#    T_i  : the number of epochs between two warm restarts\n",
    "#    T_0  : number of epochs before the 1st warm restart\n",
    "#    T_mult: T_i is defined as T_i = T_mult * T_{i-1}\n",
    "#\n",
    "# # - 3. MultiStepLR\n",
    "# gamma_G = .3\n",
    "# milestones_G = [int(num_epochs/9), int(num_epochs/3)]\n",
    "# lr_scheduler_G = torch.optim.lr_scheduler.MultiStepLR(optimizer_G, milestones_G, gamma=gamma_G, last_epoch=-1, verbose=False)\n",
    "# # At epoch in `milestones`, lr is multiplied by `gamma`\n",
    "# # - 4\n",
    "# lr_scheduler_G = None\n",
    "# ...\n",
    "\n",
    "# Optimizer for rnn_E\n",
    "# -------------------\n",
    "# # - 1. Stochastic Gradient Descent (SGD)\n",
    "# lr_E = 0.3             # learning rate\n",
    "# weight_decay_E = 0.001 # L2-regularization\n",
    "# momentum_E = 0.0       # momentum\n",
    "# optimizer_E = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "# - 2. Adam\n",
    "lr_E = 0.0025           # learning rate; default: lr=0.001\n",
    "betas_E = (0.9, 0.999)   # betas parameters; default: betas=(0.9, 0.999)\n",
    "eps_E = 1.e-8          # epsilon parameter; default: 1.e-8\n",
    "weight_decay_E = 0.0   # L2-regularization; default: 0.0\n",
    "optimizer_E = torch.optim.Adam(rnn_E.parameters(), lr=lr_E, betas=betas_E, eps=eps_E, weight_decay=weight_decay_E)\n",
    "# ...\n",
    "\n",
    "# Learning rate scheduler for rnn_E\n",
    "# ---------------------------------\n",
    "# # - 1. CosineAnnealingLR\n",
    "# lr_init_E = lr_E\n",
    "# T_max_E = num_epochs\n",
    "# eta_min_E = lr_init_E / 10.\n",
    "# lr_scheduler_E = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_E, T_max=T_max_E, eta_min=eta_min_E, last_epoch=-1, verbose=False)\n",
    "# # Essentially, with eta_max = lr_init, at epoch t, the learning rate is set to\n",
    "# #    eta_t = eta_min + 1/2 * (eta_max - eta_min) * (1 + cos(t/T_max*pi))\n",
    "#\n",
    "# - 2. CosineAnnealingWarmRestarts\n",
    "lr_init_E = lr_E\n",
    "eta_min_E = lr_init_E / 10.\n",
    "T_mult_E = 2\n",
    "nrestart_E = 3\n",
    "T_0_E = int(np.ceil(num_epochs * (T_mult_E-1) / (T_mult_E**(nrestart_E+1)-1)))\n",
    "lr_scheduler_E = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer_E, T_0=T_0_E, T_mult=T_mult_E, eta_min=eta_min_E, last_epoch=-1, verbose=False)\n",
    "# Essentially, with eta_max = lr_init, at epoch t, the learning rate is set to\n",
    "#    eta_t = eta_min + 1/2 * (eta_max - eta_min) * (1 + cos(T_cur/T_i*pi))\n",
    "# where\n",
    "#    T_cur: the number of epochs since the last restart\n",
    "#    T_i  : the number of epochs between two warm restarts\n",
    "#    T_0  : number of epochs before the 1st warm restart\n",
    "#    T_mult: T_i is defined as T_i = T_mult * T_{i-1}\n",
    "#\n",
    "# # - 3. MultiStepLR\n",
    "# gamma_E = .3\n",
    "# milestones_E = [int(num_epochs/9), int(num_epochs/3)]\n",
    "# lr_scheduler_E = torch.optim.lr_scheduler.MultiStepLR(optimizer_E, milestones_E, gamma=gamma_E, last_epoch=-1, verbose=False)\n",
    "# # At epoch in `milestones`, lr is multiplied by `gamma`\n",
    "# # - 4\n",
    "# lr_scheduler_E = None\n",
    "# ...\n",
    "\n",
    "# ----\n",
    "# # Note: to compute the sequence of lr used (for rnn_G), and plot it: \n",
    "# lr_used_G = []\n",
    "# for i in range(num_epochs):\n",
    "#     lr_used_G.append(lr_scheduler_G.get_last_lr()[0])\n",
    "#     optimizer_G.step()\n",
    "#     lr_scheduler_G.step()\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "# ========\n",
    "\n",
    "# Create Data Loader\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train\n",
    "t1 = time.time()\n",
    "loss_cur, lr_used_G_cur, lr_used_E_cur = \\\n",
    "    train_rnn_model_graph_gen(\n",
    "        rnn_G, \n",
    "        rnn_E, \n",
    "        data_loader,\n",
    "        optimizer_G,\n",
    "        optimizer_E,\n",
    "        lr_scheduler_G=lr_scheduler_G,\n",
    "        lr_scheduler_E=lr_scheduler_E,\n",
    "        return_lr=True,\n",
    "        return_loss=True,\n",
    "        num_epochs=num_epochs,\n",
    "        print_epoch=print_epoch,\n",
    "        # device=torch.device('cpu')\n",
    "        device=torch.device('cuda:0')\n",
    "    )\n",
    "t2 = time.time()\n",
    "\n",
    "# Update lists of loss, lr\n",
    "loss = loss + loss_cur # concatenate list\n",
    "\n",
    "lr_used_G = lr_used_G + lr_used_G_cur # concatenate list\n",
    "lr_used_E = lr_used_E + lr_used_E_cur # concatenate list\n",
    "\n",
    "# Print elapsed time and result of last epoch\n",
    "print(f'Elapsed time for {num_epochs} epochs: {t2-t1:.3g} s')\n",
    "print(f'Last epoch, loss = {loss_cur[-1]:.5g}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot loss...')\n",
    "\n",
    "# Plot loss\n",
    "# ---------\n",
    "color_train = 'tab:blue'\n",
    "\n",
    "figsize = figsize_lh3\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(loss, ls='-', color=color_train, label='loss')\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('loss')\n",
    "\n",
    "if save_fig_png:\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_dir}/{fig_prefix}_{fig_counter:02d}_graphRNN_loss.png')\n",
    "    fig_counter = fig_counter+1\n",
    "\n",
    "if plt_show:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot loss (log scale)...')\n",
    "\n",
    "# Plot loss (log scale along y axis)\n",
    "# ---------\n",
    "color_train = 'tab:blue'\n",
    "\n",
    "figsize = figsize_lh3\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(loss, ls='-', color=color_train, label='loss')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('loss')\n",
    "\n",
    "if save_fig_png:\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_dir}/{fig_prefix}_{fig_counter:02d}_graphRNN_loss_logscale.png')\n",
    "    fig_counter = fig_counter+1\n",
    "\n",
    "if plt_show:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot loss (part) (log scale)...')\n",
    "\n",
    "nskip_beg = int(0.3*num_epochs)\n",
    "nskip_end = 0\n",
    "\n",
    "color_train = 'tab:blue'\n",
    "\n",
    "figsize = figsize_lh3\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(np.arange(nskip_beg, num_epochs-nskip_end), loss[nskip_beg:num_epochs-nskip_end], ls='-', color=color_train, label='loss')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('loss')\n",
    "\n",
    "if save_fig_png:\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_dir}/{fig_prefix}_{fig_counter:02d}_graphRNN_loss_logscale_zoom1.png')\n",
    "    fig_counter = fig_counter+1\n",
    "\n",
    "if plt_show:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plot lr...')\n",
    "\n",
    "# Plot learning rate (lr)\n",
    "# -----------------------\n",
    "color_lr_G = 'green'\n",
    "color_lr_E = 'orange'\n",
    "\n",
    "figsize = figsize_lh3\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(lr_used_G, ls='-', color=color_lr_G, label='lr rnn_G')\n",
    "plt.plot(lr_used_E, ls='-', color=color_lr_E, label='lr rnn_E')\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('lr')\n",
    "\n",
    "if save_fig_png:\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_dir}/{fig_prefix}_{fig_counter:02d}_graphRNN_lr.png')\n",
    "    fig_counter = fig_counter+1\n",
    "\n",
    "if plt_show:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test / Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test / check : generate graph...')\n",
    "\n",
    "n_graph = 1\n",
    "max_n_nodes = 2*data_set_n_nodes_max # should not be reached...\n",
    "\n",
    "torch.random.manual_seed(2304)\n",
    "\n",
    "G_gen_list, adj_seq_array_gen = generate_graph(\n",
    "    rnn_G,\n",
    "    rnn_E,\n",
    "    max_n_nodes=max_n_nodes,\n",
    "    n_graph=n_graph,\n",
    "    force_node1=False,\n",
    "    return_encoded=True,\n",
    "    device=torch.device('cuda:0')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test / check on generated graph...')\n",
    "\n",
    "k = 0 # Index of generated graph\n",
    "\n",
    "G = G_gen_list[k]                    # generated graph\n",
    "adj_seq_array = adj_seq_array_gen[k] # generated encoded adjacency matrix\n",
    "\n",
    "# Get adjacency matrix from generated graph\n",
    "adj_mat_csr_1 = networkx.adjacency_matrix(G)\n",
    "# Encode it\n",
    "max_prev_node = rnn_G.input_size\n",
    "adj_seq_array_1 = encode_adj(adj_mat_csr_1, max_prev_node=max_prev_node)\n",
    "\n",
    "# Get adjacency matrix from generated encoded adjacency matrix\n",
    "adj_mat_csr_2 = decode_adj(adj_seq_array)\n",
    "# Get corresponding graph\n",
    "G_2 = networkx.from_scipy_sparse_array(adj_mat_csr_2)\n",
    "\n",
    "# Check\n",
    "print('Same encoding  \"adj_seq_array\" ?', np.all(adj_seq_array == adj_seq_array_1))\n",
    "print('Same adj. mat. \"adj_mat_csr\"   ?', np.all(adj_mat_csr_1.toarray() == adj_mat_csr_2.toarray()))\n",
    "print('Same graph     \"G\"             ?', np.all(\n",
    "    (np.all(np.asarray(list(G.nodes)) == np.asarray(list(G_2.nodes))),\n",
    "     np.all(np.asarray(list(G.edges)) == np.asarray(list(G_2.edges))))\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test / check : plot generated graph (topology)...')\n",
    "\n",
    "# For plotting graphs\n",
    "kwds = kwds_multi.copy()\n",
    "\n",
    "figsize = figsize_lh3\n",
    "# -----\n",
    "\n",
    "k = 0 # Index of generated graph\n",
    "G = G_gen_list[k] # generated graph\n",
    "\n",
    "# Get adjacency matrix from generated graph\n",
    "adj_mat_csr = networkx.adjacency_matrix(G)\n",
    "# Encode it\n",
    "max_prev_node = rnn_G.input_size\n",
    "adj_seq_array = encode_adj(adj_mat_csr, max_prev_node=max_prev_node)\n",
    "\n",
    "# Plot\n",
    "plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "networkx.draw(G, with_labels=False, **kwds)\n",
    "plt.title('Generated graph')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(adj_mat_csr.toarray(), interpolation='none')\n",
    "plt.title(f'Adjacency matrix, bw={csr_array_bw(adj_mat_csr)}')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(adj_seq_array, origin='upper', extent=[0.5, adj_seq_array.shape[1]+0.5, adj_seq_array.shape[0]+0.5, 0.5], interpolation='none')\n",
    "# plt.title(f'Encoded adj. matrix (max_prev_node={max_prev_node})(row by row):\\n node i (i-th row) is linked to prev. nodes i-j (j-th col) ?')\n",
    "plt.title(f'Encoded adj. matrix\\nmax_prev_node={max_prev_node}')\n",
    "\n",
    "if save_fig_png:\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_dir}/{fig_prefix}_{fig_counter:02d}_gen_graph_check_{k}.png')\n",
    "    fig_counter = fig_counter+1\n",
    "\n",
    "if plt_show:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save / Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Save / export the data set (graphRNN)...')\n",
    "\n",
    "# Save data set\n",
    "with open(filename_data_set, 'wb') as f: pickle.dump(data_set, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model (hyper parameters and parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Save / export the model (hyper parameters and parameters)...')\n",
    "\n",
    "# Save model\n",
    "\n",
    "# rnn_G \n",
    "# =====\n",
    "# Hyper parameters (design of the model)\n",
    "with open(filename_hyper_param_G, 'w') as f: f.write(str(rnn_G_hyper_params).replace(',', ',\\n'))\n",
    "\n",
    "# Model parameters\n",
    "torch.save(rnn_G.state_dict(), filename_param_G)\n",
    "\n",
    "# rnn_E \n",
    "# =====\n",
    "# Hyper parameters (design of the model)\n",
    "with open(filename_hyper_param_E, 'w') as f: f.write(str(rnn_E_hyper_params).replace(',', ',\\n'))\n",
    "\n",
    "# Model parameters\n",
    "torch.save(rnn_E.state_dict(), filename_param_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Save / export loss and lr...')\n",
    "\n",
    "# Save loss and lr\n",
    "with open(filename_loss_lr, 'wb') as f: pickle.dump((loss, lr_used_G, lr_used_E), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Display the model (graphRNN)...')\n",
    "\n",
    "print('\\n')\n",
    "print('rnn_G\\n-----')\n",
    "print(rnn_G)\n",
    "print(f'Number of (learnable) params: {nb_net_params(rnn_G)}')\n",
    "\n",
    "print('\\n')\n",
    "print('rnn_E\\n-----')\n",
    "print(rnn_E)\n",
    "print(f'Number of (learnable) params: {nb_net_params(rnn_E)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_G.state_dict() # display parameters\n",
    "# rnn_E.state_dict() # display parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
